{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Convolutional Set Transformer (cstmodels)","text":"<p>The cstmodels package provides the reference implementation of the Convolutional Set Transformer (Chinello &amp; Boracchi, 2025). It includes reusable Keras 3 layers for building CST architectures, and provides an easy interface to load and use CST-15, the first set-learning backbone pre-trained on ImageNet.</p> <p>If you have any questions or concerns, please feel free to contact me at federico.chinello@studbocconi.it.</p>"},{"location":"#about-csts","title":"About CSTs","text":"<p>Highlights:</p> <ul> <li>CST is a novel deep learning architecture for processing image sets of arbitrary cardinality that are visually heterogeneous yet share high-level semantics (e.g., a common category, scene, or concept).</li> <li>CST is general-purpose and supports a broad range of applications, including set-based classification tasks and Set Anomaly Detection.</li> <li>In the domain of image-set processing, CST outperforms existing set-learning approaches such as Deep Sets and Set Transformer. Unlike these methods, which are inherently opaque, CST is fully compatible with standard CNN explainability tools, including Grad-CAM.</li> <li>While Deep Sets and Set Transformer are typically trained from scratch, CST supports Transfer Learning: it can be pre-trained on large-scale datasets and then effectively adapted to diverse downstream tasks. We publicly release CST-15, the first set-learning backbone pre-trained on ImageNet.</li> </ul> <p>Want to dive deeper? Check out our paper!</p> <p></p> <p>Unlike Deep Sets and Set Transformer, which are inherently opaque, CST is fully compatible with standard CNN explainability tools. The Figure above shows Grad-CAM overlays for an image set provided as input to CST-15, with respect to the ground-truth class.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install the latest release of cstmodels from PyPI:</p> <pre><code>pip install cstmodels\n</code></pre>"},{"location":"#loading-cst-15","title":"Loading CST-15","text":"<p>Instantiate CST-15 with or without pre-trained ImageNet weights:</p> <pre><code>from cstmodels import CST15\n\nmodel = CST15(pretrained=True)\n</code></pre>"},{"location":"#building-a-cst-from-scratch","title":"Building a CST from scratch","text":"<p>The package provides the tools needed to build a Convolutional Set Transformer from the ground up, including:</p> <ul> <li>SetConv2D: the reference implementation of the SetConv2D block introduced in Chinello &amp; Boracchi, 2025.  </li> <li>SmartReshape2D: a utility layer that reshapes tensors depending on whether a set dimension is present. It automatically converts between  </li> <li><code>(batch, set_size, H, W, C)</code> \u2192 <code>(batch*set_size, H, W, C)</code> </li> <li><code>(batch*set_size, H, W, C)</code> \u2192 <code>(batch, set_size, H, W, C)</code>   This is useful when switching between layers that operate per-image and those that require an explicit set structure.</li> </ul> <pre><code>from keras import layers\nfrom cstmodels import SetConv2D, SmartReshape2D\n\ndef CST():\n    input_layer = layers.Input(shape=(None, None, None, 3))\n    # Input is: (batch_size, set_size, heigh, width, channels)\n    # We reshape to: (batch_size * set_size, heigh, width, channels)\n    x, set_size = SmartReshape2D()(input_layer)\n\n    x = SetConv2D(32, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = SetConv2D(32, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = layers.MaxPooling2D()(x)\n\n    x = SetConv2D(64, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = SetConv2D(64, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = layers.MaxPooling2D()(x)\n\n    x = SetConv2D(128, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = SetConv2D(128, 3, activation='relu', padding='same')(\n        x, set_size=set_size\n    )\n    x = layers.MaxPooling2D()(x)\n\n    x = layers.GlobalAveragePooling2D()(x) # -&gt; (batch_size * set_size, channels)\n\n    output_layer = layers.Dense(units=10, activation='softmax')(x)\n\n    model = keras.Model(inputs=input_layer, outputs=output_layer)\n\n    return model\n\nmodel = CST()\n</code></pre>"},{"location":"#tutorial-notebooks","title":"Tutorial Notebooks","text":"<p>We provide two self-contained tutorials notebooks here:</p> <ul> <li><code>cst_from_scratch.ipynb</code> demonstrates how to build and train a CST from scratch on the CIFAR-10 dataset;  </li> <li><code>cst15_transfer_learning.ipynb</code> illustrates how to adapt the pre-trained CST-15 backbone to new tasks, using colorectal histopathology images as a case study for Transfer Learning. </li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use this package in your research, please cite:</p> <pre><code>@misc{chinello2025convolutionalsettransformer,\n      title={Convolutional Set Transformer}, \n      author={Federico Chinello and Giacomo Boracchi},\n      year={2025},\n      eprint={2509.22889},\n      archivePrefix={arXiv},\n      primaryClass={cs.CV},\n      url={https://arxiv.org/abs/2509.22889}, \n}\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#cstmodels.SetConv2D","title":"<code>SetConv2D</code>","text":"<p>               Bases: <code>Layer</code></p> <p>Implementation of the SetConv2D layer. For more details see Chinello &amp; Boracchi (2025).</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>int</code> <p>Number of output filters in the convolution.</p> required <code>kernel_size</code> <code>int | tuple</code> <p>Size of the convolution kernel.</p> required <code>activation</code> <code>string | None</code> <p>Activation function to use.</p> <code>None</code> <code>mhsa_dropout</code> <code>float</code> <p>Dropout rate for the MHSA layer.</p> <code>0.0</code> <code>padding</code> <code>string</code> <p>Padding mode for convolution (<code>same</code> or <code>valid</code>).</p> <code>'same'</code> <code>strides</code> <code>int | tuple</code> <p>Stride size for convolution.</p> <code>1</code> <code>**kwargs</code> <p>Additional keyword arguments for the Layer base class.</p> <code>{}</code> Source code in <code>src/cstmodels/layers.py</code> <pre><code>@keras.utils.register_keras_serializable()\nclass SetConv2D(layers.Layer):\n    \"\"\"\n    Implementation of the SetConv2D layer. For more details see Chinello &amp; Boracchi (2025).\n\n    Args:\n        filters (int): Number of output filters in the convolution.\n        kernel_size (int | tuple): Size of the convolution kernel.\n        activation (string | None): Activation function to use.\n        mhsa_dropout (float): Dropout rate for the MHSA layer.\n        padding (string): Padding mode for convolution (`same` or `valid`).\n        strides (int | tuple): Stride size for convolution.\n        **kwargs: Additional keyword arguments for the Layer base class.\n    \"\"\"\n    def __init__(\n            self,\n            filters,\n            kernel_size,\n            activation=None,\n            mhsa_dropout=.0,\n            padding='same',\n            strides=1,\n            **kwargs\n    ):\n        super().__init__(**kwargs)\n        self.filters = filters\n        self.kernel_size = kernel_size\n        self.mhsa_dropout = mhsa_dropout\n        self.padding = padding\n        self.strides = strides\n\n        if not (activation is None or isinstance(activation, str)):\n            raise ValueError(\"Activation must be a string or None\")\n        self.activation = activation if activation else 'linear'\n\n        self.conv = layers.Conv2D(\n            self.filters,\n            self.kernel_size,\n            activation=None,\n            padding=self.padding,\n            strides=self.strides,\n            name='conv'\n        )\n        self.gap = layers.GlobalAveragePooling2D()\n        self.mha = layers.MultiHeadAttention(\n            num_heads=max(1, self.filters // CST15_MHSA_HEAD_DIM),\n            key_dim=min(self.filters, CST15_MHSA_HEAD_DIM),\n            dropout=self.mhsa_dropout,\n            name ='mhsa'\n        )\n        self.activ = layers.Activation(activation=self.activation)\n\n    def build(self, input_shape):\n        \"\"\"\n        This method simply marks the layer as built.\n\n        Args:\n            input_shape (shapelike): Shape of the input to the layer.\n        \"\"\"\n        self.built = True\n\n    def call(self, X, set_size):\n        \"\"\"\n        Main logic for the SetConv2D layer.\n\n        Args:\n            X (tensor): Input tensor of shape `(batch * set_size, H, W, C)`.\n            set_size (scalar): Size of the set dimension.\n\n        Returns:\n            X (tensor): Output tensor after applying SetConv2D operations.\n        \"\"\"\n        # 1. Convolution\n        X = self.conv(X)\n\n        # 2. Compute channel descriptors via GAP\n        Y = self.gap(X)\n\n        # 3. Compute bias adjustments via MHSA\n        Y = ops.reshape(Y, [-1, set_size, self.filters])\n        Y = self.mha(Y, Y)\n        Y = ops.reshape(Y, [-1, self.filters])\n\n        # 4. Add dynamic bias adjustments to the output of 1.\n        X = X + ops.expand_dims(ops.expand_dims(Y, axis=1), axis=1)\n\n        # 5. Activation\n        X = self.activ(X)\n\n        return X\n\n    def get_config(self):\n        \"\"\"\n        Returns the configuration of the layer for serialization.\n\n        Returns:\n            config (dict): Configuration of the layer for serialization.\n        \"\"\"\n        config = super().get_config()\n        config.update({\n            'filters': self.filters,\n            'kernel_size': self.kernel_size,\n            'activation': self.activation,\n            'mhsa_dropout': self.mhsa_dropout,\n            'padding': self.padding,\n            'strides': self.strides,\n        })\n\n        return config\n</code></pre>"},{"location":"api/#cstmodels.SetConv2D.build","title":"<code>build(input_shape)</code>","text":"<p>This method simply marks the layer as built.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>shapelike</code> <p>Shape of the input to the layer.</p> required Source code in <code>src/cstmodels/layers.py</code> <pre><code>def build(self, input_shape):\n    \"\"\"\n    This method simply marks the layer as built.\n\n    Args:\n        input_shape (shapelike): Shape of the input to the layer.\n    \"\"\"\n    self.built = True\n</code></pre>"},{"location":"api/#cstmodels.SetConv2D.call","title":"<code>call(X, set_size)</code>","text":"<p>Main logic for the SetConv2D layer.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>tensor</code> <p>Input tensor of shape <code>(batch * set_size, H, W, C)</code>.</p> required <code>set_size</code> <code>scalar</code> <p>Size of the set dimension.</p> required <p>Returns:</p> Name Type Description <code>X</code> <code>tensor</code> <p>Output tensor after applying SetConv2D operations.</p> Source code in <code>src/cstmodels/layers.py</code> <pre><code>def call(self, X, set_size):\n    \"\"\"\n    Main logic for the SetConv2D layer.\n\n    Args:\n        X (tensor): Input tensor of shape `(batch * set_size, H, W, C)`.\n        set_size (scalar): Size of the set dimension.\n\n    Returns:\n        X (tensor): Output tensor after applying SetConv2D operations.\n    \"\"\"\n    # 1. Convolution\n    X = self.conv(X)\n\n    # 2. Compute channel descriptors via GAP\n    Y = self.gap(X)\n\n    # 3. Compute bias adjustments via MHSA\n    Y = ops.reshape(Y, [-1, set_size, self.filters])\n    Y = self.mha(Y, Y)\n    Y = ops.reshape(Y, [-1, self.filters])\n\n    # 4. Add dynamic bias adjustments to the output of 1.\n    X = X + ops.expand_dims(ops.expand_dims(Y, axis=1), axis=1)\n\n    # 5. Activation\n    X = self.activ(X)\n\n    return X\n</code></pre>"},{"location":"api/#cstmodels.SetConv2D.get_config","title":"<code>get_config()</code>","text":"<p>Returns the configuration of the layer for serialization.</p> <p>Returns:</p> Name Type Description <code>config</code> <code>dict</code> <p>Configuration of the layer for serialization.</p> Source code in <code>src/cstmodels/layers.py</code> <pre><code>def get_config(self):\n    \"\"\"\n    Returns the configuration of the layer for serialization.\n\n    Returns:\n        config (dict): Configuration of the layer for serialization.\n    \"\"\"\n    config = super().get_config()\n    config.update({\n        'filters': self.filters,\n        'kernel_size': self.kernel_size,\n        'activation': self.activation,\n        'mhsa_dropout': self.mhsa_dropout,\n        'padding': self.padding,\n        'strides': self.strides,\n    })\n\n    return config\n</code></pre>"},{"location":"api/#cstmodels.SmartReshape2D","title":"<code>SmartReshape2D</code>","text":"<p>               Bases: <code>Layer</code></p> <p>Reshapes 4D or 5D tensors to handle an explicit set dimension.</p> <p>This layer is useful when working with data that may or may not have a set dimension (e.g., <code>(batch * set_size, H, W, C)</code> vs. <code>(batch, set_size, H, W, C)</code>). It automatically infers the correct shape and reshapes the input tensor accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Keyword arguments for the Layer base class.</p> <code>{}</code> Source code in <code>src/cstmodels/layers.py</code> <pre><code>@keras.utils.register_keras_serializable()\nclass SmartReshape2D(layers.Layer):\n    \"\"\"\n    Reshapes 4D or 5D tensors to handle an explicit set dimension.\n\n    This layer is useful when working with data that may or may not have a set dimension\n    (e.g., `(batch * set_size, H, W, C)` vs. `(batch, set_size, H, W, C)`).\n    It automatically infers the correct shape and reshapes the input tensor accordingly.\n\n    Args:\n        **kwargs: Keyword arguments for the Layer base class.\n    \"\"\"\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        pass\n\n    def build(self, input_shape):\n        \"\"\"\n        This method simply marks the layer as built.\n\n        Args:\n            input_shape (shapelike): Shape of the input to the layer.\n        \"\"\"\n        self.built = True\n\n    def call(self, x, set_size=None):\n        \"\"\"\n        Main logic for the SmartReshape2D layer.\n\n        If the input tensor has 5 dimensions, it is assumed to be in the format\n        `(batch, set_size, H, W, C)` and is reshaped to\n        `(batch * set_size, H, W, C)`.\n\n        If the input tensor has 4 dimensions, it is assumed to be in the format\n        `(batch * set_size, H, W, C)` and is reshaped to\n        `(batch, set_size, H, W, C)`, where `set_size` is provided as an argument.\n\n        Args:\n            x (tensor): Input tensor of shape `(batch * set_size, H, W, C)`\n                        or `(batch, set_size, H, W, C)`.\n            set_size (scalar): Size of the set dimension (required if input is 4D, optional if 5D)\n              or `None`.\n\n        Returns:\n            x (tensor): The reshaped tensor.\n            set_size (scalar): The set size.\n        \"\"\"\n        tensor_shape = ops.shape(x)\n        height = tensor_shape[-3]\n        width = tensor_shape[-2]\n        channels = tensor_shape[-1]\n        n_dims = ops.ndim(x)\n\n        if n_dims == 5:\n            # Input is already in (batch, set_size, height, width, channels) format\n            # -&gt; Flatten the set dimension\n            target_shape = (-1, height, width, channels)\n            set_size = ops.shape(x)[1] # Extract set_size from the input shape\n        else:\n            # Input is in (batch * set_size, height, width, channels) format\n            # -&gt; Reshape to include set dimension\n            target_shape = (-1, set_size, height, width, channels)\n\n        x = ops.reshape(x, target_shape)\n\n        return x, set_size\n\n    def get_config(self):\n        \"\"\"\n        Returns the configuration of the layer for serialization.\n\n        Returns:\n            config (dict): Configuration of the layer for serialization.\n        \"\"\"\n        config = super().get_config()\n        return config\n</code></pre>"},{"location":"api/#cstmodels.SmartReshape2D.build","title":"<code>build(input_shape)</code>","text":"<p>This method simply marks the layer as built.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>shapelike</code> <p>Shape of the input to the layer.</p> required Source code in <code>src/cstmodels/layers.py</code> <pre><code>def build(self, input_shape):\n    \"\"\"\n    This method simply marks the layer as built.\n\n    Args:\n        input_shape (shapelike): Shape of the input to the layer.\n    \"\"\"\n    self.built = True\n</code></pre>"},{"location":"api/#cstmodels.SmartReshape2D.call","title":"<code>call(x, set_size=None)</code>","text":"<p>Main logic for the SmartReshape2D layer.</p> <p>If the input tensor has 5 dimensions, it is assumed to be in the format <code>(batch, set_size, H, W, C)</code> and is reshaped to <code>(batch * set_size, H, W, C)</code>.</p> <p>If the input tensor has 4 dimensions, it is assumed to be in the format <code>(batch * set_size, H, W, C)</code> and is reshaped to <code>(batch, set_size, H, W, C)</code>, where <code>set_size</code> is provided as an argument.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>tensor</code> <p>Input tensor of shape <code>(batch * set_size, H, W, C)</code>         or <code>(batch, set_size, H, W, C)</code>.</p> required <code>set_size</code> <code>scalar</code> <p>Size of the set dimension (required if input is 4D, optional if 5D) or <code>None</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>x</code> <code>tensor</code> <p>The reshaped tensor.</p> <code>set_size</code> <code>scalar</code> <p>The set size.</p> Source code in <code>src/cstmodels/layers.py</code> <pre><code>def call(self, x, set_size=None):\n    \"\"\"\n    Main logic for the SmartReshape2D layer.\n\n    If the input tensor has 5 dimensions, it is assumed to be in the format\n    `(batch, set_size, H, W, C)` and is reshaped to\n    `(batch * set_size, H, W, C)`.\n\n    If the input tensor has 4 dimensions, it is assumed to be in the format\n    `(batch * set_size, H, W, C)` and is reshaped to\n    `(batch, set_size, H, W, C)`, where `set_size` is provided as an argument.\n\n    Args:\n        x (tensor): Input tensor of shape `(batch * set_size, H, W, C)`\n                    or `(batch, set_size, H, W, C)`.\n        set_size (scalar): Size of the set dimension (required if input is 4D, optional if 5D)\n          or `None`.\n\n    Returns:\n        x (tensor): The reshaped tensor.\n        set_size (scalar): The set size.\n    \"\"\"\n    tensor_shape = ops.shape(x)\n    height = tensor_shape[-3]\n    width = tensor_shape[-2]\n    channels = tensor_shape[-1]\n    n_dims = ops.ndim(x)\n\n    if n_dims == 5:\n        # Input is already in (batch, set_size, height, width, channels) format\n        # -&gt; Flatten the set dimension\n        target_shape = (-1, height, width, channels)\n        set_size = ops.shape(x)[1] # Extract set_size from the input shape\n    else:\n        # Input is in (batch * set_size, height, width, channels) format\n        # -&gt; Reshape to include set dimension\n        target_shape = (-1, set_size, height, width, channels)\n\n    x = ops.reshape(x, target_shape)\n\n    return x, set_size\n</code></pre>"},{"location":"api/#cstmodels.SmartReshape2D.get_config","title":"<code>get_config()</code>","text":"<p>Returns the configuration of the layer for serialization.</p> <p>Returns:</p> Name Type Description <code>config</code> <code>dict</code> <p>Configuration of the layer for serialization.</p> Source code in <code>src/cstmodels/layers.py</code> <pre><code>def get_config(self):\n    \"\"\"\n    Returns the configuration of the layer for serialization.\n\n    Returns:\n        config (dict): Configuration of the layer for serialization.\n    \"\"\"\n    config = super().get_config()\n    return config\n</code></pre>"},{"location":"api/#cstmodels.CST15","title":"<code>CST15(pretrained=True)</code>","text":"<p>Loads or builds the CST15 model. In both cases, the model is compiled with Adam optimizer and Categorical Crossentropy loss.</p> <p>Parameters:</p> Name Type Description Default <code>pretrained</code> <code>bool</code> <p>If <code>True</code>, loads CST15 pretrained on ImageNet. If <code>False</code>, builds a new CST15 model from scratch.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>model</code> <code>KerasModel</code> <p>The CST15 model instance.</p> Source code in <code>src/cstmodels/models.py</code> <pre><code>def CST15(pretrained=True):\n    \"\"\"\n    Loads or builds the CST15 model. In both cases, the model is compiled\n    with Adam optimizer and Categorical Crossentropy loss.\n\n    Args:\n        pretrained (bool): If `True`, loads CST15 pretrained on ImageNet.\n            If `False`, builds a new CST15 model from scratch.\n\n    Returns:\n        model (KerasModel): The CST15 model instance.\n    \"\"\"\n    if not isinstance(pretrained, bool):\n        raise ValueError(\"Pretrained must be a boolean value\")\n\n    if pretrained:\n        # Load the pretrained model\n        path = keras.utils.get_file('CST15.keras', origin=CST15_URL)\n        model = keras.saving.load_model(path)\n        return model\n\n    # Build a new model\n    model = _build_CST15()\n    model.compile(\n        optimizer='adam',\n        loss='CategoricalCrossentropy',\n        metrics=['accuracy']\n    )\n\n    return model\n</code></pre>"}]}